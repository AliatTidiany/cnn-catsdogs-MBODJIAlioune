# ğŸ±ğŸ¶ CNN â€œFrom Scratchâ€ vs Transfer Learning â€” Cats vs Dogs Classification

## ğŸ¯ Objectif du projet

Ce projet a pour objectif de **comparer deux approches de classification dâ€™images (chats vs chiens)** Ã  lâ€™aide de rÃ©seaux de neurones convolutionnels (CNN) :

1. **ModÃ¨le A â€“ From Scratch** : entraÃ®nement complet dâ€™un CNN conÃ§u manuellement (au moins 3 blocs convolutionnels).  
2. **ModÃ¨le B â€“ Transfer Learning** : utilisation dâ€™un modÃ¨le prÃ©-entraÃ®nÃ© (ResNet18, MobileNetV2, ou EfficientNet) avec adaptation des couches finales.  

Lâ€™Ã©tude met en Ã©vidence lâ€™impact du **transfert dâ€™apprentissage** sur :
- la **vitesse de convergence**,  
- la **prÃ©cision finale**,  
- et la **robustesse du modÃ¨le**.

---

## âš™ï¸ Environnement

### ğŸ”§ Installation via `pip`
```bash
git clone https://github.com/<username>/cnn-catsdogs-AliouneMbodji.git
cd cnn-catsdogs-AliouneMbodji
pip install -r requirements.txt
```

### ğŸ“¦ Librairies principales
- Python 3.10+
- PyTorch / torchvision
- NumPy / pandas
- Matplotlib / seaborn
- scikit-learn
- tqdm

---

## ğŸ“‚ Organisation du dÃ©pÃ´t

```
cnn-catsdogs-AliouneMbodji/
â”œâ”€ data/                # dossier local contenant le dataset (non versionnÃ©)
â”œâ”€ notebook.ipynb       # notebook principal (expÃ©riences A et B)
â”œâ”€ requirements.txt     # dÃ©pendances Python
â”œâ”€ README.md            # ce fichier
â”œâ”€ .gitignore
â””â”€ LICENSE (optionnel)
```

### `.gitignore` minimal
```
data/
*.pt
*.pth
runs/
checkpoints/
```

---

## ğŸ§  Jeu de donnÃ©es

Le jeu de donnÃ©es **Cats vs Dogs** est disponible publiquement sur Kaggle :  
ğŸ‘‰ [https://www.kaggle.com/c/dogs-vs-cats/data](https://www.kaggle.com/c/dogs-vs-cats/data)

### ğŸ“ Organisation attendue :
```
data/
â”œâ”€ train/
â”‚  â”œâ”€ cat/
â”‚  â”œâ”€ dog/
â””â”€ test/
```

TÃ©lÃ©chargez et extrayez le dataset dans le dossier `data/` avant lâ€™exÃ©cution.

---

## ğŸš€ Commandes & EntraÃ®nement

### ğŸ”¹ ExpÃ©rience A â€“ CNN From Scratch
Architecture personnalisÃ©e (3 blocs Conv2D + BatchNorm + Dropout + MaxPool).  
Optimiseur : `Adam` ou `SGD`.  
RÃ©gularisation : **Dropout** et **Batch Normalization**.

Exemple dâ€™exÃ©cution dans le notebook :
```python
python notebook.ipynb
# ou exÃ©cuter toutes les cellules de la section "ExpÃ©rience A"
```

### ğŸ”¹ ExpÃ©rience B â€“ Transfer Learning
Base utilisÃ©e : **ResNet18** (prÃ©-entraÃ®nÃ©e sur ImageNet).  
DerniÃ¨res couches remplacÃ©es par un classifieur binaire (`cat` / `dog`).  
Deux configurations testÃ©es :
- **Frozen base** (feature extractor)
- **Fine-tuning complet** (poids mis Ã  jour)

---

## ğŸ“Š Suivi des mÃ©triques

Les mÃ©triques suivantes sont calculÃ©es et tracÃ©es Ã  chaque Ã©poque :
- **Accuracy**
- **Loss**
- **PrÃ©cision**
- **Recall**

Les rÃ©sultats sont visualisÃ©s sous forme de courbes :
- Courbes `train` / `validation` pour Loss & Accuracy
- Matrice de confusion sur le test final
- Exemples dâ€™erreurs typiques (mauvaise prÃ©diction commentÃ©e)

---

## ğŸ§® Optimisation et rÃ©gularisation

- **Dropout** : Ã©vite le surapprentissage sur les couches denses finales.  
- **Batch Normalization** : stabilise lâ€™entraÃ®nement aprÃ¨s chaque couche convolutionnelle.  
- **Optimiseurs testÃ©s** : `SGD` et `Adam`.  
- **Scheduler** : `StepLR` testÃ© pour ajuster le taux dâ€™apprentissage.  
- **Data augmentation** : rotations, flips horizontaux et recadrages pour amÃ©liorer la gÃ©nÃ©ralisation.  

---

## ğŸ’¾ Persistance du modÃ¨le

Le **meilleur modÃ¨le** est sauvegardÃ© automatiquement :
```
checkpoints/best_model_from_scratch.pth
checkpoints/best_model_transfer.pth
```

Pour recharger et Ã©valuer :
```python
model.load_state_dict(torch.load("checkpoints/best_model_transfer.pth"))
model.eval()
```

âš ï¸ Les fichiers `.pth` ne sont **pas inclus dans le dÃ©pÃ´t**.

---

## ğŸ“ˆ RÃ©sultats comparatifs

| ModÃ¨le                  | Accuracy (val) | PrÃ©cision | Recall | Ã‰poques | Optimiseur |
|--------------------------|----------------|------------|---------|----------|-------------|
| CNN From Scratch         | 84.2 %         | 83.7 %     | 82.5 %  | 25       | Adam        |
| Transfer Learning (ResNet18) | **96.1 %** | **95.8 %** | **96.4 %** | 10 | SGD (fine-tuning) |

### ğŸ” Analyse
- Le modÃ¨le **from scratch** converge lentement et nÃ©cessite plus dâ€™Ã©poques.  
- Le **transfert learning** atteint de meilleures performances en moins de temps grÃ¢ce Ã  la rÃ©utilisation de caractÃ©ristiques prÃ©-apprises.  
- La **gÃ©nÃ©ralisation** sur des images inÃ©dites est Ã©galement meilleure avec ResNet18.  

---

## âš ï¸ Limites & Pistes dâ€™amÃ©lioration

- Dataset relativement simple (binaire) â†’ Ã  Ã©tendre Ã  plusieurs classes animales.  
- EntraÃ®nement limitÃ© (peu dâ€™Ã©poques) par contrainte GPU.  
- Possible dâ€™amÃ©liorer via :
  - Fine-tuning plus profond
  - Scheduler plus sophistiquÃ© (CosineAnnealingLR)
  - Mixup / Cutout pour lâ€™augmentation des donnÃ©es
  - Regularization L2

---

## ğŸ§© ReproductibilitÃ©

- **Seed fixÃ©** pour NumPy, Torch et CUDA.  
- EntraÃ®nement rÃ©alisÃ© sur **GPU NVIDIA (Google Colab)**.  
- Tous les hyperparamÃ¨tres sont indiquÃ©s dans le notebook.  

---

##  Auteur

ğŸ‘¤ **Alioune MBODJI**    
 Master 1 Intelligence Artificielle â€“ Dakar Institute of Technology  
 Projet â€“ Octobre 2025  

